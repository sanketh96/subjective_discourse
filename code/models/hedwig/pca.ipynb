{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/subjective/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from datasets.bert_processors.abstract_processor import convert_examples_to_features\n",
    "from datasets.bert_processors.congressional_hearing_explanations_processor import CongressionalHearingExplanationsProcessor\n",
    "from models.bert_hier.model import RobertaHierarchical\n",
    "from transformers import RobertaTokenizer\n",
    "from torch.utils.data import DataLoader, SequentialSampler, TensorDataset\n",
    "import os\n",
    "import models.args\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args():\n",
    "    command = '--dataset CongressionalHearingExplanations --model-family roberta --model roberta-base --max-seq-length 512 --evaluate-test --patience 30 --lr 3e-5 --warmup-proportion 0.1 --weight-decay 0.1 --batch-size 1 --epochs 30 --seed 1234 --metrics-json metrics_roberta_hierarchical_student_expert_7_concat_test.json --first-input-column 16 --use-second-input --second-input-column 2 --use-third-input --third-input-column 38 --use_expert_model --expert_model_path_fold_0 ./model_checkpoints/bert/CongressionalHearingFoldsExplanations/fold0/2022-12-08_00-00-16.pt --expert_model_path_fold_1 ./model_checkpoints/bert/CongressionalHearingFoldsExplanations/fold1/2022-12-08_01-20-56.pt --expert_model_path_fold_2 ./model_checkpoints/bert/CongressionalHearingFoldsExplanations/fold2/2022-12-08_02-43-36.pt --expert_model_path_fold_3 ./model_checkpoints/bert/CongressionalHearingFoldsExplanations/fold3/2022-12-08_04-05-10.pt'\n",
    "    parser = models.args.get_args()\n",
    "    parser.add_argument('--model', default=None, type=str, required=True)\n",
    "    parser.add_argument('--model-family', type=str, default='bert', choices=['bert', 'xlnet', 'roberta', 'albert', 'deberta'])\n",
    "    parser.add_argument('--dataset', type=str, default='SST-2', choices=['SST-2', 'AGNews', 'Reuters',\n",
    "                                                                         'CongressionalHearing', 'CongressionalHearingExplanations',\n",
    "                                                                         'CongressionalHearingBinary', 'AAPD', 'IMDB',\n",
    "                                                                         'Yelp2014'])\n",
    "    parser.add_argument('--save-path', type=str, default=os.path.join('model_checkpoints', 'bert'))\n",
    "    parser.add_argument('--cache-dir', default='cache', type=str)\n",
    "    parser.add_argument('--trained-model', default=None, type=str)\n",
    "    parser.add_argument('--fp16', action='store_true', help='use 16-bit floating point precision')\n",
    "\n",
    "    parser.add_argument('--max-seq-length',\n",
    "                        default=128,\n",
    "                        type=int,\n",
    "                        help='The maximum total input sequence length after WordPiece tokenization. \\n'\n",
    "                             'Sequences longer than this will be truncated, and sequences shorter \\n'\n",
    "                             'than this will be padded.')\n",
    "\n",
    "    parser.add_argument('--weight-decay', type=float, default=0.01)\n",
    "    parser.add_argument('--warmup-proportion',\n",
    "                        default=0.1,\n",
    "                        type=float,\n",
    "                        help='Proportion of training to perform linear learning rate warmup for')\n",
    "\n",
    "    parser.add_argument('--gradient-accumulation-steps',\n",
    "                        type=int,\n",
    "                        default=1,\n",
    "                        help='Number of updates steps to accumulate before performing a backward/update pass')\n",
    "\n",
    "    parser.add_argument('--loss-scale',\n",
    "                        type=float,\n",
    "                        default=0,\n",
    "                        help='Loss scaling to improve fp16 numeric stability. Only used when fp16 set to True.\\n'\n",
    "                             '0 (default value): dynamic loss scaling.\\n'\n",
    "                             'Positive power of 2: static loss scaling value.\\n')\n",
    "\n",
    "    parser.add_argument('--pos-weights',\n",
    "                        type=str,\n",
    "                        default=None,\n",
    "                        help='Comma-separated weights for positive examples in each class to use during the loss')\n",
    "    parser.add_argument('--pos-weights-coarse',\n",
    "                        type=str,\n",
    "                        default=None,\n",
    "                        help='Comma-separated weights for positive examples in each coarse class to use during the loss')\n",
    "    parser.add_argument('--loss', type=str, default='cross-entropy',\n",
    "                        choices=['cross-entropy', 'mse'],\n",
    "                        help='Loss to use during training for multi-label classification.')\n",
    "    parser.add_argument('--num-coarse-labels',\n",
    "                        type=int,\n",
    "                        default=3,\n",
    "                        help='Number of coarse-grained labels.')\n",
    "    parser.add_argument('--id-column', type=int, default=0)\n",
    "    parser.add_argument('--label-column', type=int, default=1)\n",
    "    parser.add_argument('--first-input-column', type=int, default=2)\n",
    "    parser.add_argument('--use-second-input', action='store_true')\n",
    "    parser.add_argument('--second-input-column', type=int, default=3)\n",
    "    parser.add_argument('--use-third-input', action='store_true')\n",
    "    parser.add_argument('--third-input-column', type=int, default=12)\n",
    "    parser.add_argument('--use-fourth-input', action='store_true')\n",
    "    parser.add_argument('--fourth-input-column', type=int, default=12)\n",
    "    parser.add_argument('--num_train_restarts', type=int, default=3)\n",
    "    parser.add_argument('--use_expert_model', action='store_true')\n",
    "#     parser.add_argument('--expert_model_path', type=str, default=None)\n",
    "    parser.add_argument('--expert_model_path_fold_0', type=str, default=None)\n",
    "    parser.add_argument('--expert_model_path_fold_1', type=str, default=None)\n",
    "    parser.add_argument('--expert_model_path_fold_2', type=str, default=None)\n",
    "    parser.add_argument('--expert_model_path_fold_3', type=str, default=None)\n",
    "    parser.add_argument('--finetune_last_layers_only', action='store_true')\n",
    "    parser.add_argument('--num_last_layers', type=int, default=None)\n",
    "    args = parser.parse_args(command.split())\n",
    "    return args\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = get_args()\n",
    "args.fold_num = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_vocab_path = args.model\n",
    "tokenizer = RobertaTokenizer.from_pretrained(pretrained_vocab_path)\n",
    "model = torch.load('./model_checkpoints/bert/CongressionalHearingFoldsExplanations/fold0/2022-12-08_00-00-16.pt').to('cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting test examples...\n",
      "Gold Label:  gold_labels_binary\n",
      "Document Index:  qa_index_digits\n",
      "First Input:  gold_sentiments_coarse_num\n",
      "Second Input:  r_text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5863/1032700982.py:13: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  label_ids_fine = torch.tensor([f.label_id for f in eval_features], dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "processor = CongressionalHearingExplanationsProcessor(args)\n",
    "eval_examples = processor.get_test_examples(args.data_dir, is_expert=False)\n",
    "eval_features = convert_examples_to_features(eval_examples, args.max_seq_length,\n",
    "                                                     tokenizer, use_guid=True)\n",
    "\n",
    "unpadded_input_ids = [f.input_ids for f in eval_features]\n",
    "unpadded_input_mask = [f.input_mask for f in eval_features]\n",
    "unpadded_segment_ids = [f.segment_ids for f in eval_features]\n",
    "\n",
    "padded_input_ids = torch.tensor(unpadded_input_ids, dtype=torch.long)\n",
    "padded_input_mask = torch.tensor(unpadded_input_mask, dtype=torch.long)\n",
    "padded_segment_ids = torch.tensor(unpadded_segment_ids, dtype=torch.long)\n",
    "label_ids_fine = torch.tensor([f.label_id for f in eval_features], dtype=torch.long)\n",
    "doc_ids = torch.tensor([f.guid for f in eval_features], dtype=torch.long)\n",
    "\n",
    "eval_data = TensorDataset(padded_input_ids, padded_input_mask, padded_segment_ids, label_ids_fine, doc_ids)\n",
    "eval_sampler = SequentialSampler(eval_data)\n",
    "eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=args.batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_tokens = []\n",
    "labels = [] # first class only\n",
    "model.to('cpu').eval()\n",
    "with torch.no_grad():\n",
    "    for step, batch in enumerate(tqdm(eval_dataloader)):\n",
    "        batch = tuple(t.to('cpu') for t in batch)\n",
    "        input_ids, input_mask, segment_ids, label_ids, doc_ids = batch\n",
    "        logits_coarse, logits_fine, output = model(input_ids=input_ids, attention_mask=input_mask, token_type_ids=segment_ids)  # batch-size, num_classes\n",
    "        cls_token = output[:, 0, :]\n",
    "        cls_tokens.append(cls_token.cpu())\n",
    "        labels.append(label_ids[:,0].cpu()) # first class only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 768)\n",
      "(200,)\n"
     ]
    }
   ],
   "source": [
    "rep_array = torch.cat(cls_tokens).numpy()\n",
    "print(rep_array.shape)\n",
    "labels_arr = torch.cat(labels).numpy()\n",
    "print(labels_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to reduce dimensions of representations using sci-kit learn pca\n",
    "def reduce_dimensions(data, dimensions):\n",
    "    pca = PCA(n_components=dimensions)\n",
    "    pca.fit(data)\n",
    "    return pca.transform(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = reduce_dimensions(rep_array, 2)\n",
    "plt.scatter(x[:,0], x[:,1], c=labels_arr)\n",
    "plt.title('PCA of the CLS representation for class 1')\n",
    "plt.xlabel('First Principal Component')\n",
    "plt.ylabel('Second Principal Component')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('subjective')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "819055562185c9b00a15ffe1c0e875ecededb30ef60912f03753ddf35e600fdb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
